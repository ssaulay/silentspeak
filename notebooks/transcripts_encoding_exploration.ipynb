{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words-to-Phonems\n",
    "import lirecouleur.word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cd .. && tree "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand English - Alignments by nicknochnack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/nicknochnack/LipNet/blob/main/LipNet.ipynb\n",
    "\n",
    "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]\n",
    "\n",
    "char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token=\"\")\n",
    "num_to_char = tf.keras.layers.StringLookup(\n",
    "    vocabulary=char_to_num.get_vocabulary(), oov_token=\"\", invert=True\n",
    ")\n",
    "\n",
    "def load_alignments(path:str): \n",
    "    with open(path, 'r') as f: \n",
    "        lines = f.readlines() \n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        line = line.split()\n",
    "        if line[2] != 'sil': \n",
    "            tokens = [*tokens,' ',line[2]]\n",
    "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd'), (5, 'e'), (6, 'f'), (7, 'g'), (8, 'h'), (9, 'i'), (10, 'j'), (11, 'k'), (12, 'l'), (13, 'm'), (14, 'n'), (15, 'o'), (16, 'p'), (17, 'q'), (18, 'r'), (19, 's'), (20, 't'), (21, 'u'), (22, 'v'), (23, 'w'), (24, 'x'), (25, 'y'), (26, 'z'), (27, \"'\"), (28, '?'), (29, '!'), (30, '1'), (31, '2'), (32, '3'), (33, '4'), (34, '5'), (35, '6'), (36, '7'), (37, '8'), (38, '9'), (39, ' ')]\n"
     ]
    }
   ],
   "source": [
    "print([(i+1, char) for i, char in enumerate(vocab)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 23750 sil\n",
    "# 23750 29500 bin\n",
    "# 29500 34000 blue\n",
    "# 34000 35500 at\n",
    "# 35500 41000 f\n",
    "# 41000 47250 two\n",
    "# 47250 53000 now\n",
    "# 53000 74500 sil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(21,), dtype=int64, numpy=\n",
       "array([ 2,  9, 14, 39,  2, 12, 21,  5, 39,  1, 20, 39,  6, 39, 20, 23, 15,\n",
       "       39, 14, 15, 23])>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_path = os.path.join(os.getcwd(), \"..\", \"raw_data\", \"Sample_English\", \"align\", \"bbaf2n.align\")\n",
    "load_alignments(alignment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 23750 sil\\n', '23750 29500 bin\\n', '29500 34000 blue\\n', '34000 35500 at\\n', '35500 41000 f\\n', '41000 47250 two\\n', '47250 53000 now\\n', '53000 74500 sil\\n']\n",
      "-----------------------\n",
      "[]\n",
      "-----------------------\n",
      "line --> ['0', '23750', 'sil']\n",
      "all tokens from begining --> []\n",
      "-------\n",
      "line --> ['23750', '29500', 'bin']\n",
      "all tokens from begining --> [' ', 'bin']\n",
      "-------\n",
      "line --> ['29500', '34000', 'blue']\n",
      "all tokens from begining --> [' ', 'bin', ' ', 'blue']\n",
      "-------\n",
      "line --> ['34000', '35500', 'at']\n",
      "all tokens from begining --> [' ', 'bin', ' ', 'blue', ' ', 'at']\n",
      "-------\n",
      "line --> ['35500', '41000', 'f']\n",
      "all tokens from begining --> [' ', 'bin', ' ', 'blue', ' ', 'at', ' ', 'f']\n",
      "-------\n",
      "line --> ['41000', '47250', 'two']\n",
      "all tokens from begining --> [' ', 'bin', ' ', 'blue', ' ', 'at', ' ', 'f', ' ', 'two']\n",
      "-------\n",
      "line --> ['47250', '53000', 'now']\n",
      "all tokens from begining --> [' ', 'bin', ' ', 'blue', ' ', 'at', ' ', 'f', ' ', 'two', ' ', 'now']\n",
      "-------\n",
      "line --> ['53000', '74500', 'sil']\n",
      "all tokens from begining --> [' ', 'bin', ' ', 'blue', ' ', 'at', ' ', 'f', ' ', 'two', ' ', 'now']\n",
      "-------\n",
      "-----------------------\n",
      "tf.Tensor([ 2  9 14 39  2 12 21  5 39  1 20 39  6 39 20 23 15 39 14 15 23], shape=(21,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "with open(alignment_path, 'r') as f: \n",
    "    lines = f.readlines() \n",
    "    \n",
    "print(lines)\n",
    "print(\"-----------------------\")\n",
    "\n",
    "tokens = []\n",
    "\n",
    "print(tokens)\n",
    "print(\"-----------------------\")\n",
    "\n",
    "for line in lines:\n",
    "    line = line.split()\n",
    "    print(f\"line --> {line}\")\n",
    "    if line[2] != 'sil': \n",
    "        tokens = [*tokens,' ',line[2]]\n",
    "    print(f\"all tokens from begining --> {tokens}\")\n",
    "    print(\"-------\")\n",
    "\n",
    "print(\"-----------------------\")\n",
    "\n",
    "final_result = char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]\n",
    "print(final_result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# French"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "phon_transcripts = os.path.join(os.getcwd(), \"..\", \"raw_data\", \"sample\", \"transcripts\", \"phonetique\")\n",
    "full_transcripts = os.path.join(os.getcwd(), \"..\", \"raw_data\", \"sample\", \"transcripts\", \"complet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_phon = os.path.join(phon_transcripts, \"8.txt\")\n",
    "test_full = os.path.join(full_transcripts, \"8.wav.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Words to phonems with LireCouleur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', '0.0', 'sil'], ['un', 'four', 'tofu'], ['1.4', '1.4', 'sil']]\n",
      "\n",
      "['un', 'four', 'tofu']\n",
      "[('x~', 'un')]\n",
      "[('f', 'f'), ('u', 'ou'), ('r', 'r')]\n",
      "[('t', 't'), ('o', 'o'), ('f', 'f'), ('y', 'u')]\n"
     ]
    }
   ],
   "source": [
    "with open(test_full, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.split() for line in lines]\n",
    "\n",
    "print(lines)\n",
    "print(\"\")\n",
    "\n",
    "words = lines[1]\n",
    "print(words)\n",
    "\n",
    "for word in words:\n",
    "    print(lirecouleur.word.phonemes(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0'],\n",
       " ['0'],\n",
       " ['0', '</s>'],\n",
       " ['0.18', 'U~'],\n",
       " ['0.27', 'f'],\n",
       " ['0.41', 'u'],\n",
       " ['0.48', 'R'],\n",
       " ['0.55', 't'],\n",
       " ['0.61', 'u'],\n",
       " ['0.72', 'f'],\n",
       " ['0.85', 'y'],\n",
       " ['0.91', '</s>'],\n",
       " ['0']]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(test_phon, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    lines = [line.split() for line in lines]\n",
    "\n",
    "lines\n",
    "# words = lines[1]\n",
    "# print(words)\n",
    "\n",
    "# for word in words:\n",
    "#     print(lirecouleur.word.phonemes(word))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://keras.io/examples/audio/ctc_asr/#:~:text=CTC%20is%20an%20algorithm%20used,transcript%20align%20to%20the%20audio"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "silentspeak",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
